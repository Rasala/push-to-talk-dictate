# üéôÔ∏è Dictate - Push-to-Talk Voice Dictation for macOS

A local, privacy-first voice dictation app for macOS using Apple Silicon. Hold a key to speak, release to transcribe and type directly into any application.

## ‚ú® Features

- **Push-to-Talk**: Hold Left Option (‚å•) to record, release to transcribe
- **Local Processing**: All transcription and cleanup runs on-device using MLX
- **Auto-Type**: Transcribed text is typed directly into the focused window
- **Smart Cleanup**: Uses Qwen LLM to fix grammar and punctuation
- **Multiple Microphones**: Choose from any connected audio input device
- **Clipboard Backup**: Text is also copied to clipboard

## üîß Requirements

- macOS with Apple Silicon (M1/M2/M3/M4)
- Python 3.11+
- ffmpeg (for audio processing)
- Accessibility permissions (for keyboard control)

## üì¶ Installation

### 1. Install ffmpeg

```bash
brew install ffmpeg
```

### 2. Set up Python environment

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -U pip
```

### 3. Install dependencies

```bash
pip install mlx mlx-whisper mlx-lm
pip install sounddevice numpy scipy pynput pyperclip
```

### 4. Grant permissions

When you first run the app, macOS will ask for:
- **Accessibility**: To detect key presses and type text
- **Microphone**: To record audio

## üöÄ Usage

```bash
source .venv/bin/activate
python ptt_dictate.py
```

Or run as a module:

```bash
python -m dictate
```

### Controls

| Action | Key |
|--------|-----|
| **Start Recording** | Hold Left Option (‚å•) |
| **Stop & Transcribe** | Release Option |
| **Quit** | Cmd + Esc or Ctrl+C |

### Configuration via Environment Variables

```bash
# Set specific microphone (device index shown at startup)
export DICTATE_AUDIO_DEVICE=3

# Output mode: 'type' (default) or 'clipboard'
export DICTATE_OUTPUT_MODE=clipboard

# Transcription language
export DICTATE_LANGUAGE=pl

# Disable LLM text cleanup (use raw Whisper output)
export DICTATE_LLM_CLEANUP=false

# Disable verbose logging
export DICTATE_VERBOSE=false
```

### Programmatic Configuration

```python
from dictate import DictationApp, Config
from dictate.config import OutputMode

config = Config()
config.audio.device_id = 3
config.output_mode = OutputMode.CLIPBOARD
config.whisper.language = "pl"
config.llm.enabled = False

app = DictationApp(config)
app.run()
```

## üìÅ Project Structure

```
dictate/
‚îú‚îÄ‚îÄ __init__.py      # Package exports
‚îú‚îÄ‚îÄ __main__.py      # Module entry point
‚îú‚îÄ‚îÄ app.py           # Main application orchestration
‚îú‚îÄ‚îÄ audio.py         # Audio capture, VAD, device enumeration
‚îú‚îÄ‚îÄ config.py        # Configuration dataclasses
‚îú‚îÄ‚îÄ output.py        # Output handlers (typing, clipboard)
‚îî‚îÄ‚îÄ transcribe.py    # Whisper + LLM transcription pipeline
```

## üèóÔ∏è How It Works

1. **Recording**: Audio is captured while you hold the Option key
2. **VAD**: Voice activity detection segments speech from silence
3. **Whisper**: MLX-optimized Whisper Large V3 transcribes audio locally
4. **Qwen Cleanup**: Qwen 2 1.5B fixes grammar/punctuation errors
5. **Output**: Text is typed into the focused window (and copied to clipboard)

## üé§ Supported Models

- **Transcription**: `mlx-community/whisper-large-v3-mlx`
- **Text Cleanup**: `Qwen/Qwen2-1.5B-Instruct-MLX`

## üìù License

MIT

### Dependency Licenses

| Package | License |
|---------|---------|
| mlx, mlx-whisper, mlx-lm | MIT |
| sounddevice | MIT |
| scipy, numpy, psutil | BSD-3-Clause |
| pyperclip | BSD |
| pynput | LGPLv3 |

### Model Licenses

| Model | License |
|-------|---------|
| whisper-large-v3-mlx | MIT |
| Qwen2-1.5B-Instruct-MLX | Apache-2.0 |

All dependencies are compatible with the MIT license of this project.