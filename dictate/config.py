"""Configuration for the Dictate application."""

from __future__ import annotations

import os
from dataclasses import dataclass, field
from enum import Enum
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from pynput.keyboard import Key

from pynput import keyboard


class OutputMode(str, Enum):
    TYPE = "type"
    CLIPBOARD = "clipboard"


class LLMModel(str, Enum):
    PHI3 = "phi3"
    QWEN = "qwen"


@dataclass
class AudioConfig:
    sample_rate: int = 16_000
    channels: int = 1
    block_ms: int = 30
    device_id: int | None = None

    @property
    def block_size(self) -> int:
        return int(self.sample_rate * (self.block_ms / 1000.0))


@dataclass
class VADConfig:
    rms_threshold: float = 0.012
    silence_timeout_s: float = 2.0
    pre_roll_s: float = 0.25
    post_roll_s: float = 0.15


@dataclass
class ToneConfig:
    enabled: bool = True
    start_hz: int = 880
    stop_hz: int = 440
    duration_s: float = 0.04
    volume: float = 0.15


@dataclass
class WhisperConfig:
    model: str = "mlx-community/whisper-large-v3-mlx"
    language: str | None = None


# Language name mapping for LLM prompts
LANGUAGE_NAMES = {
    "en": "English",
    "pl": "Polish",
    "de": "German",
    "fr": "French",
    "es": "Spanish",
    "it": "Italian",
    "pt": "Portuguese",
    "nl": "Dutch",
    "ja": "Japanese",
    "zh": "Chinese",
    "ko": "Korean",
    "ru": "Russian",
}


@dataclass
class LLMConfig:
    enabled: bool = True
    model_choice: LLMModel = LLMModel.QWEN
    max_tokens: int = 300
    temperature: float = 0.0
    output_language: str | None = None

    @property
    def model(self) -> str:
        if self.model_choice == LLMModel.PHI3:
            return "mlx-community/Phi-3-mini-4k-instruct-4bit"
        else:  # QWEN
            return "mlx-community/Qwen2.5-3B-Instruct-4bit"

    def get_system_prompt(self, output_language: str | None = None) -> str:
        target_lang = output_language if output_language is not None else self.output_language
        
        if target_lang:
            lang_name = LANGUAGE_NAMES.get(target_lang, target_lang)
            translation_instruction = (
                f"TRANSLATE the input text to {lang_name}. "
                f"Output the translation in {lang_name} language only. "
            )
        else:
            translation_instruction = ""

        if self.model_choice == LLMModel.PHI3:
            return (
                f"{translation_instruction}"
                "You are a speech-to-text post-processor. Your job is to fix "
                "punctuation, capitalization, and obvious transcription errors. "
                "Output ONLY the corrected text. Do NOT answer questions. "
                "Do NOT add commentary. Do NOT explain. Do NOT converse. "
                "Just output the cleaned-up version of the input text, nothing else."
            )
        else:  # QWEN
            return (
                f"{translation_instruction}"
                "You are a text processor. Return ONLY the processed text. "
                "NO preamble. NO 'Sure', 'Here is', or any introduction. "
                "Fix punctuation and capitalization."
            )

    @property
    def system_prompt(self) -> str:
        return self.get_system_prompt()

@dataclass
class KeybindConfig:
    ptt_key: "Key" = field(default_factory=lambda: keyboard.Key.alt_l)
    quit_key: "Key" = field(default_factory=lambda: keyboard.Key.esc)
    quit_modifier: "Key" = field(default_factory=lambda: keyboard.Key.cmd)


@dataclass
class Config:
    audio: AudioConfig = field(default_factory=AudioConfig)
    vad: VADConfig = field(default_factory=VADConfig)
    tones: ToneConfig = field(default_factory=ToneConfig)
    whisper: WhisperConfig = field(default_factory=WhisperConfig)
    llm: LLMConfig = field(default_factory=LLMConfig)
    keybinds: KeybindConfig = field(default_factory=KeybindConfig)
    output_mode: OutputMode = OutputMode.TYPE
    min_hold_to_process_s: float = 0.25
    verbose: bool = True

    @classmethod
    def from_env(cls) -> "Config":
        config = cls()

        if device := os.environ.get("DICTATE_AUDIO_DEVICE"):
            config.audio.device_id = int(device)

        if mode := os.environ.get("DICTATE_OUTPUT_MODE"):
            config.output_mode = OutputMode(mode.lower())

        if lang := os.environ.get("DICTATE_INPUT_LANGUAGE"):
            config.whisper.language = None if lang.lower() == "auto" else lang

        if lang := os.environ.get("DICTATE_OUTPUT_LANGUAGE"):
            config.llm.output_language = None if lang.lower() == "auto" else lang

        if verbose := os.environ.get("DICTATE_VERBOSE"):
            config.verbose = verbose.lower() in ("1", "true", "yes")

        # LLM cleanup
        if llm_enabled := os.environ.get("DICTATE_LLM_CLEANUP"):
            config.llm.enabled = llm_enabled.lower() in ("1", "true", "yes")

        # LLM model choice
        if llm_model := os.environ.get("DICTATE_LLM_MODEL"):
            try:
                config.llm.model_choice = LLMModel(llm_model.lower())
            except ValueError:
                pass  # Keep default if invalid value
        return config